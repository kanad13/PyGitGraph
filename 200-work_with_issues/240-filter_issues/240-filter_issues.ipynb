{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# purpose\n",
        "\n",
        "- fetch last 100 github issues\n",
        "- try various ways to filter & search through them\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# structure\n",
        "\n",
        "- **fetch issues**\n",
        "  - fetch the last 10 open and closed issues\n",
        "  - that allows me to close open issues or reopen closed issues\n",
        "- **dataframe data**\n",
        "  - make a pandas dataframe from the data fetched from github\n",
        "  - this is a nested dictionary - each comment and lable is a node inside the corresponding issue\n",
        "  - so the comments and labels have been exploded into their own separate lines\n",
        "- **search dataframe**\n",
        "  - try scalar value search\n",
        "  - try filtering with multiple parameters\n",
        "  - use query api\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fetch github token, python packages, queries and other parameters\n",
        "\n",
        "%run ../../100-set_parameters/100-set_parameters.ipynb # magic commands"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# fetch issues\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# query parameters\n",
        "# specify the query parameters to be used while fetching issues\n",
        "# github does not allow fetching more than 100 issues\n",
        "\n",
        "fetch_issue_parameters = {\n",
        "    \"repository_name\": \"tensorflow\",\n",
        "    \"owner_name\": \"tensorflow\",\n",
        "    \"number_of_issues\": 100\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# store result\n",
        "\n",
        "last_few_issues = global_query(fetch_recent_issues, fetch_issue_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## dictionary to dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drill down\n",
        "# take the dictionary result from previous step\n",
        "# reach out to a particular level within that dictionary (edges in this case)\n",
        "# store that inside a dataframe\n",
        "\n",
        "df = pd.DataFrame(d['node'] for d in last_few_issues['data']['repository']['issues']['edges'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## flatten nested data\n",
        "\n",
        "- GitHub responds with a nested structure for the query above.\n",
        "- in this response, each issue may contain various sub-elements, such as labels and comments\n",
        "- for example, an issue might have the following structure:\n",
        "\n",
        "```json\n",
        "{\n",
        "\t\"id\": \"issue-id\",\n",
        "\t\"title\": \"Example Issue\",\n",
        "\t\"labels\": [{ \"name\": \"bug\" }, { \"name\": \"enhancement\" }],\n",
        "\t\"comments\": [{ \"body\": \"This is a comment.\" }, { \"body\": \"Another comment.\" }]\n",
        "}\n",
        "```\n",
        "\n",
        "- in this nested structure, labels and comments are each grouped under a single issue, but for visualizations, we need to flatten this structure or explode it\n",
        "- if an issue has multiple labels or comments, we want each label or comment to be represented as a separate record associated with the issue\n",
        "- to achieve this, we can use the following code to flatten the nested data into a DataFrame, enabling easy visualization and analysis:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## comments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# access comments\n",
        "\n",
        "df['comments'] = df['comments'].str['edges']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# flatten comments\n",
        "\n",
        "# the comments for each issue are nested under the 'comments' key\n",
        "# code below extracts the nested comments and flatten them into a simpler structure\n",
        "\n",
        "df_flat_comments = df.explode('comments')\n",
        "df_flat_comments['comments'] = df_flat_comments['comments'].str['node'].str['body']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# access labels\n",
        "df_flat_comments['labels'] = df_flat_comments['labels'].str['edges']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# flatten labels\n",
        "\n",
        "df_flat_comments_and_labels = df_flat_comments.explode('labels')\n",
        "df_flat_comments_and_labels['labels'] = df_flat_comments_and_labels['labels'].str['node'].str['name']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## final dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print to screen\n",
        "\n",
        "df=df_flat_comments_and_labels\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# search dataframe\n",
        "\n",
        "- the previous steps covered\n",
        "  - fetching data from graphql api server\n",
        "  - putting the response inside a dataframe\n",
        "  - flattening it out\n",
        "- the next steps involve\n",
        "  - searching through the dataframe\n",
        "  - i will also use the DataFrames Query API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## searching syntax\n",
        "\n",
        "- the pandas equivalent to sql query\n",
        "  - `select * from table where column_name = some_value`\n",
        "- is\n",
        "  - for single condition\n",
        "    - `table[table.column_name == some_value]`\n",
        "  - for multiple conditions\n",
        "    - `table[(table.column_name == some_value) | (table.column_name2 == some_value2)]`\n",
        "- check [stackoverflow](https://stackoverflow.com/a/31296878) for more details\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## scalar-value search\n",
        "\n",
        "- to select rows whose column value equals a scalar, some_value, use `==`\n",
        "- in the next 2 sections have examples for\n",
        "  - search for an integer\n",
        "  - search for a string\n",
        "- check [stackoverflow](https://stackoverflow.com/a/17071908) for more details\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# scalar-search integer\n",
        "\n",
        "df.loc[df['number'] > 13].head(3) # github issue number\n",
        "#note that github fetches only 100 records at a time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# scalar-search string\n",
        "\n",
        "df.loc[df['labels'] == \"type:bug\"].head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## iterable\n",
        "\n",
        "- search for a list of values within a particular column\n",
        "- [link](https://stackoverflow.com/a/17071908)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# code\n",
        "\n",
        "df.loc[df['labels'].isin([\"type:bug\", \"type:build/install\"])].head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## multiple conditions\n",
        "\n",
        "- notice how 2 conditions have been used for searching through the dataframe\n",
        "- one condition involves a search string & the other has an integer\n",
        "- [link](https://stackoverflow.com/a/17071908)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# code\n",
        "\n",
        "df.loc[(df['labels'] == \"type:build/install\") & (df['labels'] == \"subtype: ubuntu/linux\")]#.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# negtation\n",
        "\n",
        "- search for rows whose value DOES NOTE equal to the search input\n",
        "- 2 examples given below\n",
        "  - search for scalar values\n",
        "  - search for iterable values\n",
        "- [link](https://stackoverflow.com/a/17071908)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# scalar\n",
        "\n",
        "df.loc[df['labels'] != \"type:bug\"].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# iterable\n",
        "\n",
        "df.loc[~df['labels'].isin([\"type:bug\", \"type:build/install\"])].head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## query api\n",
        "\n",
        "- `DataFrame.query()` is a method of pandas\n",
        "- it is used to query the rows based on the expression (single or multiple column conditions)\n",
        "- in case i want to update the previously created DataFrame `df`, then i use `inplace=True` argument for the method\n",
        "- links\n",
        "  - [sparkbyexamples-df_query_api](https://sparkbyexamples.com/pandas/pandas-dataframe-query-examples/)\n",
        "  - [geeksforgeeks-df_query_api](https://www.geeksforgeeks.org/python-filtering-data-with-pandas-query-method/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### basic example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# code\n",
        "\n",
        "df.query('labels == \"type:build/install\"').head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### syntax\n",
        "\n",
        "- `DataFrame.query(expr, inplace=False, **kwargs)`\n",
        "- where\n",
        "  - `expr`\n",
        "    - expression takes conditions to query rows\n",
        "  - `inplace`\n",
        "    - defaults to false\n",
        "    - when set to true, it updates the referring DataFrame\n",
        "    - the query() method returns none\n",
        "  - `**kwargs` â€“ Keyword arguments that works with eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# calculate yesterday's date\n",
        "yesterday = datetime.today().date() - timedelta(days=1)\n",
        "df['createdOnDate'] = pd.to_datetime(df['createdAt']).dt.date #you can modify this to search for issues created today\n",
        "\n",
        "# use inplace\n",
        "df_inplace = df.copy() # https://www.w3schools.com/python/pandas/ref_df_copy.asp\n",
        "df_inplace.query(\"createdOnDate == @yesterday\", inplace=True)\n",
        "df_inplace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list\n",
        "\n",
        "search_list = ['type:bug', 'type:build/install']\n",
        "df.query(\"labels in @search_list\").head(3)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
